{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 00:28:24.099144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 00:28:25.233495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/wcampos/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 00:28:27.031856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.377949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.378155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.379549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.379685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.379779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.474059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.474252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.474375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 00:28:27.474521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14407 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 72 X 72\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 144\n",
      "Elements per patch: 108\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFICAYAAADd1gwNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEnElEQVR4nO29edRleVnf+9t7n/Gdq6qru6t6AG2udMNSMQK2DA1pZRLCFJCYeEWIcalrXSWKMYskKybGacUsveq6QbwOuLy5KCKDRMZmaIQWvBIUMVxomoaeqqq76p3O+55pD/mj4/t7vt99zrPPqa6OYH8/f+2nfvvs6fzO793Pt54hqaqqCkIIIWaS/m1fgBBCfCWjRVIIIRy0SAohhIMWSSGEcNAiKYQQDlokhRDCQYukEEI4aJEUQggHLZJCCOHQutgP2kQdTtpZJoknyzKwi6JwzrnENRW4c6fXBnt/9wDsz37mMzO3Qwjh9s+i/YX/Hu1eG4/7f7/9HbXr+unX/DDYj/m6xx5tX/+EJ+DY4x8PdmKPT+daaXfAHk2nYGfwCJLadeGJzDjt2m7hd5TTd+QdOWk6ryHN8G92WZS0hzcBFp9zaYbTvizz+UetFr9+hud2CCEUOT67sojnLgq8jvvuuw/se+6+62j7rrvugbHv+u7vBvvnf+bnwR4Ox0fbp6+6CsZOnz4N9qMefc3M7RBC2NjYpOMegm3vOUn42TXZkXYbv6M8x2dTP/ZiY0yaNr8n6k1SCCEctEgKIYSDFkkhhHC4aE3yYmnSC3jc6oz80bpGaXW15YoblWXUv/J8yoNgtoyO0Uqb9Q/+S5RU5ngVHruqSO+rjMZTsUbnHPfBf5mx9T/P4+hBF6/CLadBXszRI/z9Ouddci7Ac2ucc/ZTy9+7nd8lzbPJeAT2YDA42t7b23WPu7+3B7bVJHdXV2FsZWUF7K3dqDvu7w9gjDXJ0WgMdrfXPdpukfbr/fSXkBFnfPbhnHN6kxRCCBctkkII4XBJ3O1lXehLty/a1hUqyobjkN+UT6LbMDrA8KCKQmt6xt3uzwjzYLrkGmYm1CPJJ3QudF9CGj+bttjX6+GuAa8zqay7TdeZop1Y2WDJ7zNx3PqHwkNyo5K5xozzXJp3hUXcbb6noozyymSC3/2F8+fB/tIddxxtf+ELdwSPO27/PNgHh9F139nZwfNcuAD22FxHSXP3KgofOnf/A2CfPHnZ0fbKCj7XLME5l5k51ySI1OZckswdu9ToTVIIIRy0SAohhIMWSSGEcLhoTfJSpQXVPzv/WM3ZjvPDhbx9QwihMGlP09EQr4HS8Pqt+NhWWs2PsEN2ajTJaophHvkY9dAkjftmGaVsdjfArHI8VqjM38AUUxqTWuhS3Lfp0dU1yYcJ98D1oKYlPox7OpOF59xDlr/o86WZW9MJ6tM729tg33PXl4+2v/RFX5P88p13gn1wEOf07g6GD23TeWwmZkopqTc9/algnzl7DuwVE17U6eDMzzqsg5s51/DjXiR98OhYl1ij1JukEEI4aJEUQggHLZJCCOHwvzwt8VLiqRhpQ7pgi7SWlZUYc7i5iVpfvodpXGE/7ttZIC2xTVdajaM+tH/+fhg7dzfqOJ3VmObVWenC2FXXXQH29rm7wG4ZHbLdxdSz9greY8uMJ5ROltZUVcRVk1ytCccSiqOrnDTMuuzkaZSXUqPy7mf585QmTrKgmNlQoJ2Ykm6t4KeodiksNs/MtRUYTzs6xHJnZ+87c7RdNWiBd9zxRbD7/X68Xnocxza3wG4toOcfXUfFc+XhjY206E1SCCEctEgKIYTDV5m7vUT16SZ3u03udj+60Fub6zCW76yBXa5ElyIr5le1/hva5BqVJsRo/wK622WLUiDXumYb0xCvuu5bwGZ3u9uO+/fWtmBslZ6PDfVI2ZUh163i78GYNafXrVqPYymlSnJVHLwsTlOjE19sxaAGvKr7zRJA/VoqEwJUTClFlapRpcbd5jnF9DI899Q+Wpqzo0MMOztzJrrb21QFiLnji3eCfez48aPtFfM7CSGEVao2tBLi+KX7hi49epMUQggHLZJCCOGgRVIIIRySapnWhkII8QhDb5JCCOGgRVIIIRy0SAohhMNXYJzkfIm0FnPn7Mul9LlEf04xaWe+fOfR9n1f+hKMnbvj9rn2dIBxZN//y79Wu5bfes0PgN3qxMeerlE5qTVMPVw/HmPL1o9hnNlNL/oxsP/s3f8X2L1OjENb3TyBxz1xGuyVrZPx+noYJ9rtHQe7rCh9ztbWaohw8xTwjNIhC4rnWy4VbX7HQ54L9fTH+TGWfqokz7l6a4+S7mmwE1s07O9gG4XP/uWnwP70n//Z0fbdX8aY2F/4nTeD/eoXPAvs3f2YejjK8Z5GVIEvtOMcrNo4Pz/wgfeA/SOv+XGwv/lJ33y0ff1jvw7GvubR14J92Yk4J/m3zaXR6jGzD0+pxlnoTVIIIRy0SAohhIMWSSGEcPgK1CQXp0H9ckc5t3tjazOOVdg2Mx2j7ljuR+1oL7CgUydJUE8ZHuwdbY8OMT93egGPd2IcS5qVJWqFzP72PWDnnZi7nVC72U4Ptaa2sbM2tnpgEr5no/FVFf7dret0eCSPesl+28pj8fDephYM9fHKjC2uSfI7x2xpjK87Hi+pUK/stfF4x9aixjzZ8ufCqRNbdKz4U7+wh6XRpgNs+zEeR3s0Iv2ZGOzvz7WHQ2yDUuTNv5WvRPQmKYQQDlokhRDC4SvP3X4ISZLoGXElY9y3pPF2N7qYa5tYGo3tlY1YqXy4j53mZlGU6OoOTUfEcUB3Jm+hS5JP4oXTYernmezgZ6sYyjEdogs9PsRq6x1b/o263PVWMVwoz9GNsi52FbjcGV5jWcyvGL66ii7k8JC6VpqQGnbFE7KtnLJsSIhXzm3G3uZz7E7Wf14ludSFKYeWT8cwlpGssdqNxztGZfOYk+SOt80zmExwIu0NsFTaoekcOpr4JdmGVGbt8CC68uMRuvFFIXdbCCH+zqFFUgghHLRICiGEw1eeJrkMFWtNUT8pKFSD/xoUpB/ZyJW0g4+l1UU9r9OPml3aata7xtQFb2S6JQaSlkgODO1WabZ9UTJLUNNKTCe+croLY5MhapLDgQkXanNqJJ5nNNoDu6ri86poSk0n+Jwnk6h3laWvSe7s4DVnrfg9dDp4jR16cLYb5jJd+ZimSCOrX3KabD0pMYScOhVOp1G3m4xRg2URuteKx9/o+x0sL9vEFNaWubadvT0aI93R6KSTkT/nRhTmMzKtSSYTnPcFC9RfJehNUgghHLRICiGEgxZJIYRw+OrSJFkfctqVFiXGo7Uz1HCm1K4TYtwSirEkcSltRy1tEU0ypBQflkW7Q/pnd4Xsbjx+i49DZAm1IDVxdlVOqWgj1PtGB6Y8Vgv1vpMB2d/FNrhWkywr1G+HlHZ5cBA1uKLAZ3f11VhK68x9Z8Bumxa5fW5PSnbftAju9bs0hnZO6XIZpKyijlaRbcu5TSnOsb2GLVVDCOFggGl8h4M9s43fyZQ0Sqsxdxvm3RqlndqUwFUa61N75fQw3kc+wVhHZjTEeWXvb3iIY3nO+ubD1TlmmeM2/371JimEEA5aJIUQwuGryt2ue9vo+uTg+lD4BEVMcMpUKKKLUeU4ZsM0QgihMqEZWbs5rKG/iu5MkkZ3r79BKYDraK/2ozuQNfxJS0kmALvC51GMMZ1sZCob1VLRbkDzgXuwUntRxWtmd3tnB13G7e3ogk2m6Oo88ck3gv25z34O7I6ttL5GqaPraB8/fuxo+xhVxOn3LwebXcZeL34//ExLknGmk3h/u7uYorq2htXgQwjh3H1YUfzgQpQuBudRxjik4w3NdVZTvzoP/zZaZvKsrmDc2eYmhl5dGMZjV0VDCNAhVsja2Y7zaHcP5YPxGOUIW228KXX0EhcbXwq9SQohhIMWSSGEcNAiKYQQDkm1TIlnIYR4hKE3SSGEcNAiKYQQDlokhRDC4WGJk1xG5WzqXAdjJbU2KDhmLcZ3HY4w9u3kZVeA/eV7vgh2auIkkxLjuXbuvRPsC3d94Wh779y9MPb8/+MXatf9ez/1Srzuaby2lU2MWVuhOMnMtHNotfF+n/m//y7YH/1/vgfstulimFJaZtXC85ap6cQXMG3v6S/592B/4A9/Bj8bYmykjZkMIYT7H8Dv4ey5mLY2nuDf6Nf91H8A+2d/Es/T6cbUw9UNjO3boFi/U6eujNun8bu//obHgn3fPfgdbpj2HBybWhQ4Nw4P4v2cO4vHefwTnh6YD7/3zWCP9mIs5Gh3B8Yme2hPjZ1SHOQ/+snXg/2HP/Mj+Nk8/rDOnMdSafc+gOf573feY7bvhrHP33Mf2E990pPAvva66462n/TkJ8PYzTffDPbjH/+4o21ux5FluDT5XSovniRpfk/Um6QQQjhokRRCCActkkII4fBVlbvN5d+5PPxg3+hD95+DMdYkv/j5O8Be7Zrc1i4KpTnlnHZMa4CVFdTvZrG6RqW5plFb7HYxr5uqVqFmW/oJrCTZBpsazRpWQjnIRYg5yOOpXx5ruIPPtjIaZhWoRNchnidMTI78xJ9+JT33SWk01pTK2QXMMbYdN1Jq28ua5Nl7MZ96NIh54EmCz2065tJgO0fbD5zD0m6zNMmzd38JbNs6oUUtZNsdzINPTb76rNYQlv46arRd87gua1Ehgx6WdNsZx+d14QDvl+l18TscDWNNgME+ap+2tUMI+Pttt/Fe65rkpQnnXra9cAh6kxRCCBctkkII4fBV5W6X5E9OxuhG7Rl3+8y9GKrwDd/wBLDvuP0LYJ/cWp25HUIIGXU7bLeXc7fXyN2eTqJr2CLXnhv7laYjZFX5f9MKcseto5iUXEaN3G0TTjU+RDeXGW6jux0SE06U4r0WB+Te2EPnfse/grvtma+/Ihc6L6iKtykNl499l/HMvRjmMjqIrmpS4XMaHqILOdiLpcEuPHDWPU8IIZy9506wt4xbvEnl3lrkbreyOO/aqT8XenQsG+qSreBYd30DbOti37+LldRr56HK+qND424P8FkNqSTdxJQz5BCgJqBLZYMr7rnYi3jfepMUQggHLZJCCOGgRVIIIRwuWpO8dBXWWBSYf1zWFrIWBkK0jN10fTm1d9jdiaXmpweow/Qz3HclM+XtudXBDLhNQVnE60xzGmORxHTuS1JfQElT/DqtDsV6Zk765WQa72M89u9pNESdLmvlZhuvIU1QV+vZ2JwMx5guxUNVJkeQtdt2izTXKn5H5RRbVTCHe+fBLoZmLlC3wME+tlQ4PIi6G3c3nEnBnRnjPfW6qOd2KCymncbn0WrQ8NY3UWcsjSadjEjPpd/KZcc3j7YfdTWGzjFXncJemiMzrzY38Bp6FGrUMl9imjYFNeF8xZ+JN+YfZxH0JimEEA5aJIUQwkGLpBBCOHxVxUlyLFWHYrS6Jq6s1fI1joriBvd2Y2vM7RFqWBt9PO8x0yK2RXF0s6DsulAV5ngJ6ymku7ajnTZpkqTxJeZ5FQWlWpI9yaPuOp74eu5ohJplx+S8ceWpFqWX9W271sLXJHs9/GxpDt7u4onaHbyfdhq1v7Tw4z5HpDMOTLtWjvXb3Ub9cmJaytp7mwe/lXTa8R57fdTsVldWwF7pxXjUrGEurG9tgm3LCJak+4+pPe3xY+tm31Puea69+kqwB+N47BPHt2BsbRXvp9OOcbJZ5v9e67GORqt/mNvN6k1SCCEctEgKIYTDV4G7bVw5eq1ml7pn3JGtrS33qCdPXg72tqngsr27C2P7OYZtlMY7aVUYHjSLnX3cx1bk6VJ4EEWBhO5KHO9xmWwiz9ENLsx52IUejsg+jPd4OPDv6XCEz6MylXJSCsXJqXJTYVJLq6aqRiVeR2Vc6ITq4GQkxbSNO9ppcE2zCt3NySSmz5WU0lhShaTKyBRZ0uxut2nOpmZSc9hazTa3wRWxmPEEJYaxqcAzpKr9EwpdapkKS+urfuroxhpKBKlJs22TCz0YDMA+d/8DR9sc7nTFFfT73EZJJDMhQymdJ6PfiXXl2W3vdPz7C0FvkkII4aJFUgghHLRICiGEQ1JduvxCIYT4O4feJIUQwkGLpBBCOGiRFEIIh7/1Umkct1TW4r/seXCMr2E8jjFs2+cxruqqax4F9l/++Z+Dfeftn4/bn/88jE0OMW6yHMd4r5Ri+V77i78RmF/6568Cu52aOEnKzOM4yY3N+BWtb+HXdfOrfw3sd7/h1WAfmvYWB4cY2zg4wGd5aMbzCaZa/sQvvw3sn/2hF4K9uhbTzdbWsPXFtMBrHuctM4Z/o3/s534F7J/7Fz8CdmLi3fqr+OBWV/E8GysxZnaj34Ox53zPj4P9jjf8B7CHhzGO8OAAU1QPDjDWL8/js+K0wh/8d68PzBt//p+DvW7aN6xzaTG67p5JeyxynHc3vuiHwP7gf/mPYA9NW4XhEOMixyOM/SzMz4qyd8Mrf+L/BPv1P/tasA9NqunKJpZRO3nqGrCPnYixkCv07G688clg/+VffBrsrvmhdLodGpv/3Dj9cZNKys1Cb5JCCOGgRVIIIRy0SAohhMPDkru9jF7JmmT9s1E7Y72SW8yWRRxvt/wyXKur1FazGzWRVgs1jv0pnnd/N2pWxQIl+888gO0gOuZP0yqVYVvtU0sKUxKsn/t/08ZjfHYHB1GT3D9AnXFvgPuOzGezhhL3VUL5rml81gm1kEgpxzo1CcgtrqtGdDqUk2vynntUGq3bJrtlcrcbZnmX2/iaz5b04aRC7aww7RhabX/OhVBvu2DnMGuDFc3v3JQ0m0798m87u6jJW52VzzOlViZWt8sy/+GV1G55an4r29sXYGwwxPPce9/9R9trq6hlsyb52c/+/2D3jYbZ5xJzpIuvmmO3qe+HNEkhhHiIaJEUQgiHS+JuN5V4stQrDPOxqLSWcWfGVOL78JDCMwbR3tvBitKXnzoN9l133QP23p4J7UjwsXAV78FhdBsGexgSMou77nsA7FZiqjdvYrXmE8epGvWGCfso/a8rL9A9nU7j38CcXPWKXGrbua5PIRTM1jEM7Vhdi9e4SqW12DUvq3ieJPXLVF1zNVbFtiWx2h2cJ+02zjl75KyhcjWPt8w/dMnd5orgthTcQjIT7VNMTEV4GssnXPIr2tPcL2d3cIDl0KyLPaEyatw51FaTzzJ0+ZkdKmF2Zicee0CKwITnbxa/JXaZX/XqV4L90Y9+FGzbedGWSAwBw6pCCGFjI9ptkkRueNz1oQm9SQohhIMWSSGEcNAiKYQQDg+LJllPLYywJskdEKdTDFWx2guXf79wAfWQ7Qsx5GD7/A6MfdMTvxnsu750N9hjEyJRVXiNkxzvb38Ywx4u7KIuOot7zmIoRFpFnacsj8NYh/IUjxldJy/8r6ugcatDlqQHJSmFGmVRV+yvoqbDrG/hNa/047FXVkjDa2GeZZqZjn9tv93BlVeg9pm17FzB0BO2K6O7ldyukkgSnK+2+n+njc+J2y/kJm9vMmlu5VFxOwsT1lMW/HnSOM20tOmQs7AhPyGEMJ7Y8CF8VgUdqzA6JLdgYPao1cmZ++Jv8twOhhrtHeJ5bPZrt+vr05/4xP8HttUhu5TLazXIEELY3IydI9ttPA9rn7PQm6QQQjhokRRCCActkkII4fC/RJOcgB6Cusvx46hvnTlzBuwdo3mcf+A8jJ07dz/YF85H7e9gF/XLF74Ey3vdfvsXwLapeKzC7O2j7rh/EFMR94ej0MRgjBpQZlp21mLjKFVvbHSbw6HfRrSgOMlOJ6ZeJnRTHdIoKxMbyrFkTMnXbL7vCbXf7aRoJ5lJMy18XW06ofQ50xa3KKi8F9tGk8wnvia5P0D9zs7nJPgauh3lNMJZlBTfWIHuiM81Teefu2zQJHPW9m085hivgX+TPaPxZUmTDk5zwbQ1LrgVc629cNxu0nNHlEppNVkeY3t3N8ZMc6m0RdCbpBBCOGiRFEIIh0tSmZzdbZtKGAK+/nKl57q7fRbse+6992j73nvug7F770X7/P3R3Z40uMG3fx7d7XVTKWSdKpKwu70H7rbvyoUQwj652x1TZabubqM7MLLu9qHvznEIUMeEO3S6eNyS3KgyseFCfnpd3d2O1zUl9yslt75lqjpVZZO7TelzxsWaTPA7mU7RZZ6asB8+DrNPc9JWimllKD20E8fdLnw5JIQQCnJtg0nDTSglN7ToXMZVrPKGuUDnmRgXezTC+TihfVNTyandsELwLefmuoqCq3axLBftqRM2GELdhQ4NlapgT9h1+Y4KepMUQggHLZJCCOGgRVIIIRyS6lK1PRRCiL+D6E1SCCEctEgKIYSDFkkhhHBYOE7ygQewBYFNZeLYx8E+pgRu78TySdvbOzD20pe+BOzX/9obwD53NqYenj/PpdGwTNPBfoyV47Stt77z98B+yfNeDvZKz5QK62HppZ09PM+FnRiPuT/ANhF/9hdY0imEEB7/2BvAtmmJV57YhDG2L9uIMZuXbWL85ut+9XfB/pWf+H6w11ZjifuUAt4KKllXGGl6SjF4P/RvfgnP8+9+GOxeLzXbGI/Z7fTm2gklgL7wn74O7Le/4WfxGgsbg8dpamjbVh82LTaEEL7/3/wa2L/x0z8Eto2T7FDXzQ6V2rKxjbZ9SAghfPe/+tXA/PrrXgV2y6QeZvTKwm0J+v1oTyge9R++9hfB/u2fwnvaNbG9u9RyZECtHtZWYwuR1RVsJ/Jjv/BGsH/0lS8G+85742/j/B5+JwcTjIUcm86KnLL4mb/+FNiPu+Ebw3xwLnOHGFuekaMrP/2Z/+Yc90H0JimEEA5aJIUQwkGLpBBCOCysSZ49iznVNpfygftRr7yf7HP3n4vb587BGGuS/+2TqBFsb0c9cHiIObgT0jhK02Yha2hdO52i7jYoomYzGg1hbEi5v6X525J1/RYEIYTQWenTv0S9dEils+7f2cE9jZ42OfRzkM9fQK0pTaOe1i6pFWpFpbRM/vWkoV3p4GAf7KKM56kq0j5J37QlvFKu30YMh9Qaw8hwVYXXWHIrYpsX3JBTPaHxyrRzqLV2yNBOjJbb1FIhhHoJs8y0rM2opUaf2xKYVql55c/vjfUtPG8VvyPbEjmEEIpySHY8dlH571EJ1QBoQb0ArktAradNGT1uIcH4Jc7wWfC+thVvU0vrWehNUgghHLRICiGEw8Lu9l/91V+Dje42VgzncKEL2zYECDsHMnffjeXPhqbkWb2QNb5WJ2bNrxJ//WcXLDf2ZEpuArlytmRVKyzgbnfR3a6Mq1sGPPZwgufOjFtZTDBUg7l/h8az6Pp0+xjKUqUkVZjrYNeVqVUfN+XQ+LlzV8bUPLss9adfp0MdHm0oR81Vx9Cc1ITxcPhT7TzUqa8yrnpB5b04PCqY0JW8aM7wLchNLs0crlK8jkmJz/JgFM81bajKdjjGHUbmAxP6HU1JioE5mPrSy5g6idoS+FmLXHF6li3zLJqyoxOeVzAXcCzL6Lx2LsjdFkKIS4sWSSGEcNAiKYQQDgtrkrfd9gmwbfe13T1MzdvbwxARmyI2ptLxzP4e6mpWxqhpD9xNzow3qUNFTXezHfKozHxgnS2et9WgfYYQQqeNqV22bUFS+R3lDs3jmrCYRJwlTXJkNJ9+H/WuVgevu90xOmvm6zYVPY/UaJ/tDuqvXU6tM3anoSvj+tY62DaFjzsJJhReMrbdASf+nFtfXwN7aFL4OIRpTCE8pekOOG1ulhjKBO+5SOKzyxN8VpTVF7ZNSNS44WRnzuNv8GAUf4ODId7DJOcUVdOJcOr/kg6p82JpwnFYj04ofCo1P+4kb/gd1TTJzGzTfEzbZFtNcvn3Qr1JCiGEgxZJIYRw0CIphBAOC2uSn/sctmAtTNDikNqq1to/QjqZf57xGPUSjKtD7YQzsyqjSzXFXeWk/XkqXFLTv+LflkU0jlZGcXgmlauktqoVaZSQLlj4OtTOkFqFmu0utbXtdltkx+fc6/jT4oDS2tqdeA/dHsXCUTijlSFbraaYtfktVVPSTVmjbNvPpn76Y4vKoZVV1CQnOcWT0ndQmPjD6aQheDGEQNM7FGbOTiqOmcXnfGh0xXGDPn3mAv4/wcRoqSOaC+PadVvbj5M8pBuyYZNVrWbZ/OM0pQvW4iTT+fG2ac2O36/iJIUQ4hKjRVIIIRwWdre5urN1Z9MU19put0f7mu0Gj4RdH/uOzg50QamFHD7jUbC77VQvpkIwGI2wQK9JvueqsilVlHrH1U5MpZQq8++voDTNQxMmMi7RTUxJEbFhP52W/7fznjOYWjowcUqDfZRebHV0tvt9P6XzvnM7YHeNDNAiP75FZb1LI1s0zYv9A5zbh6PoQo5H6G7mlIaXm2c8YV96Btv7+ODLKj6vImDYznA8393OGyobnT2P1fRLqFZEkkGDjOMxpHue2gr3dFzvvGVjWiJV+jHuNq8ZKYce2R+sQoCEEOLSokVSCCEctEgKIYRDUjXFygghxCMYvUkKIYSDFkkhhHDQIimEEA4Lx0nedNNzwLZxSxyXxLYXJ/nBD70D7Gfc9AKwy9KmGlJXO5JTrc1xVR/92LvBfupTngu2jaXiz9ayq+w/kKL74Y+8MzA3Pe35+HlbTso7dgihMiliFbV6+PCt78LzPP1ZYNuUx6ri9EeK6TPPjrMFb73tT8H+tqc+Bez11VWzjWXhOE5yfTXG0K6sYDztT/7i68H++df9CNi9run+yHGSbY6Nq2ZuhxDC973258D+lZ96DdgHplRaLU6SSpRNJiYWleIaf+l3fi8wP/iKl4I9MumFI0o1HFJs8tCkE1InhPC+j9wK9nOf+UywEye4d5n/lHj3Bz8I9rP//s1g204QU0rp5DJzuRmnMN7wyU9+DOxv+qangt1uxRjbdhvnUS1V2Plt3/qRt4cm9CYphBAOWiSFEMJBi6QQQjgskbuNOblW4+DcSS6BBaXFMn9dbrXmX1Jdg+Txcu6+DOeb293rub7OsRYQdOq5sVaT5BYUvKs9QdPJuHyYaWdR4XOtanXm7LH9clJFhaXfbKW8skRdjqpyhYNDU1ati3OKuesezBFvm9aw3GIiq5VdK+ds1/niXefAnhhtsZZvTFKuHWdNchbnLgzwXLnJEyfNjtseT0G4878jLmHWVIrsYvflNhK2PBq3463XbTD/r9G4LvAaE+dCxvUOGp7NsuhNUgghHLRICiGEw8Lu9niMJZ7sKy6/nbMrm5lX6azptbpNpcOWeHW2bnJT+Sd+RbduU0nxCF6o0SJJnbnjbnOl5NIJP2qq8sQutA3F4srOVcUHs3qDf6KyQtfHNsAckct5QJ35sjS62FzejLnrnm38rHGx+aM05UIZTPhT8EuY3UnudlnEZ8GhNvyMCxPGMpk0u9v3X8ByaLacGFeer1X2tlpMg0t8SNeCvyOaY/RZqMTfMOnGUyo5aD7Lv426imW+z5rLjLC7nYG7zXObwuhsGKF7ltnoTVIIIRy0SAohhIMWSSGEcFhYk6yny0Xvvq7/YdyHHc9z/5QcamTLtNfTH1n7zOaOMd0utg5ot02KVOm3hbD3s0ilOdZTUNPEz3MZ+wpjk9zzTClcBVPzwtyx//kvZsvXu0rSqdJk/mfL2nnjP+QNj25MaW1J4dwPp9ol5jtqCAE6GNH37URd1cPOzP2Uvq4WQggFtesozTxNqP0Gfw0gtTVokiUdC/Zm3buuSs67hBnnobnghLex7oipzf66wKGB3rpQ+0km0iSFEOJhQ4ukEEI4aJEUQgiHhTXJNJuvThSUq8UaZZLYeD0/lmw8wnhMq+exttemmEqra3jpjSGE0Ov15o6xTsj3Y++X29rOotPB67YlomrPrqaHzo/fZCaU1gYSVi2ukGMq52tJTC1+L5uvD3mHKhsUItYsbbxbXXiiMnp2u+F+RjnH2VnN2NfvKtvyeJF2pS0q62Vz9SgosyTd2P4/QFML1sDapx2qSZDzn0/VpEq6Zcno/wxS1rLTmduzaGXz28byXGYl9aE2qNGbpBBCOGiRFEIIh4Xd7Xa7PXesrFX78NL4fPeUXcq8WDwt0b5WL1PJhPfnUAVOeyrLltludrf7fazOnRsXnVMWC646Y54Hu+ZMp4OuHDzrpsexVHgJ4Xy/Cfk6cOSGuTDlND2vyhPbNj2u4X5yTtGEQ3GaqOPaOZLU0d4kGaVO2X4Oa7LyRNLw7NLM+Wk3VN5fhqQmr1jZht1rCuGzrnlDyJ4X/tcUAlQPd1sOvUkKIYSDFkkhhHDQIimEEA5JtUhenRBCPELRm6QQQjhokRRCCActkkII4bBwnOTfv/nZYHvdBetxk3YMj3vbbbeA/a3f+m24QzU/XY5jtGz5JI7rvOUDbwP7uc95Odg2jZE/y2XXMA0Kx978B78RmJe97PvAtk+nnobIKZEmBZJiKN/9rv8C9rOe85302WLm9oPnYduUiqtw7LY/eTfY3/JUngvza4vVmz/Ol8D/lOfCjTfjDsvI57Z1BcW9fuxP3gP2U572XL7KuFWLKUzJnl8m7tYPv6N2WTc944Vg21TDisu9VZxqOb/E3m0fwe/oxqc9p3bueJ38D4sHSvJ5nvJ0fHaJE6ucclk1+x3Rb+yDH3wb2N/+bS/Fz5rvNKvFSc5/jjyF3vu+N4cm9CYphBAOWiSFEMJBi6QQQjgsrElyPrP1++u6DWkpZrghRbNW9shqdNzeM3Bub22H+Uwmk7ljzWXn57eznAWXbbP6C5eiqhUAK2xbCb9U2urqOth5MT/vO8+5vJ3RPks/R7zd7uBnvXJurKtZzarh66oPL5NkPL+1KVNyOTT4/h9CYvMMqqUO57d+9fDal9QlyIu/R9Zo8ajcY4P3nZ/n3XQeKLOWcm0F1tvna7mLoDdJIYRw0CIphBAOC7vb0ym6p07UR+2V1lYmb+piyK5tms6vEl2vFhXHm0qYsbtpr5nH6qXTTPhBQwX0EEIYUbX11HyGu8SlfP9LnKvXWwEbQka46jWHHpmwnyZ3e+vYcbCL3FZqx8rzJVVuL22nyYaq7r0u3Y+VXmrXP7/jYdEgw7B75npktS6N1mV0TxNCCGE6xW6gXHvcOVVt3IPvyeuWWO+e6F8FXhL/+M3+HC7FIUB2XUj8TpO1ive2yyR3cqVLst0Dmko1zjz30p8QQohHEFokhRDCQYukEEI4LKFJOl0Oa3ENHEJj/ru+ocR9PaRmfigHy45Wbmj6r/56mp5pqUCaJOuo9hoX0STHY9ShWkYja7U51ZLPFbWYpg6Q3W4Xj5V4uo3Xic8PNdrc2AK7yOPcyPMpjVE7DtPRscz98/R7q3gsoy15HSxDCCGHsCRfY62nsc0PGeHUQctCmmTOvyMTStfwWXv8xo6WrLPCcfxUy5Asp7PCR61GS3dUa9+Qzu+yydTaN8A1+nO7LOen5y6C3iSFEMJBi6QQQjhokRRCCIeFNUnPl6+FJJJGadO+OAWsdp4Sx1umBWdNG2QVB2I3fU2y1+u745baFZvLWKR1bUX5d1bzY72syOdHqTWdqaalXmR6XUOGWMgotjPrxA9wyiLHSVa2JFtDnOTm1jE8lv1srcQc2rnRKKcNrXiP0XlsOmfJ2mftvCbuc4EYvDa1lLWfqcf2Xnxr5pz0XjsV6u1ZKT7TpAY3tnrllN3Kxj5SnGQ6304b0nv5PAE0dBwp6bdfQGqz0hKFEOKSokVSCCEclnC3OY0vbpcl/xe8426XvttXq8hiXLuMXJUk5VAG4yY0vFV3ez38B7ghco+DkwKXLuLGzq+UzM+VI0ySJVLRCgrTKl2/mZ9ztFsNKWK1NM10viRSw0lnZTY2t+Z+1qs+HUIIUyM95IUTvhZC2NpEd9uG6XDom1dNicOfZsFV71HG8qvHe6FJjCePtVpe1aMQ7Nxo+j5rrnsw1cZrVdw5tXCJECCac1YGYQmE01ALkGnkbgshxCVFi6QQQjhokRRCCIekuphSvUII8QhBb5JCCOGgRVIIIRy0SAohhMPCcZJPe9ozwLbxRpMpxaiR3WrFVLWshWlrn/jT94L9zJtfCvbqWuwA2O7gZzmVycZ0pSS1/v6bXg/2P3rFD4ANuZW1OEmKXzNxk1w66y1veWNgXvqy7wUb4jkDx5LNL2PFpabe9Kb/DPYr6J5s6GAtnY7TBc121sJressfvAHsl7/iB8HOWqbFBH8ntS5381Pefvs3/xPYr/6nrwXbPptayltAbPoZp/v95m/+AtivfOVrwLYxhjmX1HNKtHFa6NvfXp8Lz3/BPwE7h3PN72DJdkExlB+79V1g3/jU54Btn12Hfkdsw++IvqN3vfNNYD/7ea8AO89tvUIulTa/DKCdQyGE8Mfv/B2w/8GLXkXnMc99is+Jy9HZ+NWK5sJH/+SPQhN6kxRCCActkkII4aBFUgghHBbWJFf62N4zL2w+JLabZW0mSUwL1QRzV5l2B0uY9ftRk+z2Md+6RdpZ5miSzMb6Jl6jFfCa2pUajZLzumexvoZtCKxexq1e6+15Z2/PgvOXQe+iHOTJhHKSzT03lcfa29sFu9Wary1lGU6xltWhauWvkPEE215AKws6bi2f3OhfvC/T6+Kcs6HDXFqLNS2rdxa5X5IthBA217ks2/wcc9bWpo7+yfT7OOesttjv829s8bKBTJeeXVmOzDaXYKN5BW1hl3tfs8dm3ZhDv0FXXbYfRdCbpBBCuGiRFEIIh4Xd7c1NdE8nE9P1rjyAsWk+BNu6QvUKwwi7Z7a0VIdKpXG4SWYrKjeURMr41d96Udw8jg5lh8sFKn63yJUobVXllEJxap3eFi+Pxe525XSJY3cNwk8aXBLu/jjNTffI2nfC7vfi7vbBIc4rdNXZjSf325w3ayj9Np2wPGTbEtLOtVJ2tqyYf55Z1+nB3zZ0PGyYd1wh3rqc3S7KVmxbCaFpzvF3mDidFr2QPa8LZQgzQthsRXe+RjovdA1dovTg36A3SSGEcNAiKYQQDlokhRDCYWGB5NgxDF0Yj2PYzzRHP39EGo/trteoSXJLBrvN0kO9TdrRJqdtMVyWP4AOg/oH6xjWXqRDXsh5H3s8Tg+cr0nWu+nRUVmTBNtTuJbrxFdLlzO759ztMZmfmsbtN5jBYB8/azSsmtbJHRyN3Ur9aV4/j20rsHirg0WqDrIW7LUW4PCwZYoa1jqL2v8XSOdrgw+eZ5k5R78N6MqIz4r1S3veppCm6RTDDAsz6ZJarxb+zuaPLYLeJIUQwkGLpBBCOGiRFEIIh4U1yVrqktGW2h2MX2xx7JSJj2pqUVnTfGw8FLdfLXDfwmopvC/BsX5VFTVMTj1LOM0J7GahaDwagW11x5L0lOIhaJJ5jrqN3b2ms9Ziyey+7mlmtHOdH8tZ1/AWZ0TPDUqlsSaZzNcomzTJw0OM6221jIZO87WmsTa10CWmpL3Z77SW/lpy3Ovi8Yse9Vjc+edtmnM8/zFOkp/V/LnQPLfn/57rc2y+Tnox6E1SCCEctEgKIYTDwu42u6eTSXTtOCSEX+cz87qbZf67r3V7Q8D/+ueq0FxBvALXxQ8BOhxhyhtWfWa3nlzVfH640Cx2d7FqDqQlUggQu9voyvrnqbmNJgWOP8opYm1TqYlTwBgO5YBrdK5/eVh6gQPTEJ/XVOdpCAfjlE17rFoF9Frl+Pnu5Sy4ijam19FcoHlYWEmo4bl67qv97c7ad5kQIB63UgVfYl2mMdW0+DfXcB4IB6vNR5YPirlji6A3SSGEcNAiKYQQDlokhRDCIakemmgkhBB/p9GbpBBCOGiRFEIIBy2SQgjhsHCc5Ktf9c/AtqXSLmxjHODu3gDsdieWh291ujB2y3veAvbzXvBPwO604/5JhXFoZY7xbVB2PsF4qP/6X38X7O94wXeBbVP6cupSV1JsWzWZn8J468ffF5ibbnwWft7E4RUUJ1nW4v2shff/8Y9/AM9z0/PA7vViKmmWYeoox/RV5tgcJ/ned/8e2N/+7JfjNUN8qh8n6aUwfuRDbwf76c98UZiHV4LtQduUBqN3gfffgvfz7GfhXIBybk5cJNs89s4/fmPtuv/B878XbBsbWXHMrBfvR/Pk/e/5fbC//TnfOfc6vZJlTfzxH+Hv6Pkv/B6wbfsO/t8Ojke1NsdufvD9fwD205/5YrBtewrb4uXB41JrEvN75jjJD3/gbaEJvUkKIYSDFkkhhHDQIimEEA4La5JeXmpOGsB4jCWuCpNj3eL8a2I0OgQbNT9qzZrzseJ5Ol2/TUSnTTm5Rj+puP1qgXrJZBLz2Lnk/ixGE8x7t9Ii61C+Junj5dBzzny95Wh8XkXDPa2sYNk8KOe2RBmuphDdTgev0a1KV+sqatuIPsRaWQuySO42t6zIzHVWfJ2cZpwsnlPNLJOPvVw+On3fUK6Q6zCg1o8aZUPr2ha3JrZl83Bfvr1lygDOQm+SQgjhoEVSCCEcLo27TSEzozGW7MrMa3WroWI4f9a+HSe0pnO1YttpsdvrBY9uhzrEmTf/IuHQInS3R5N4jUWxQGXyKVXYTm2YBHdL5LJVthuffx52t62/llFpNHZlbRhFk4KwsrKCZ3Gqp3M4kXWxmty+bhfDxcBVL323HsLFKt9lZHfckwG838Ei7jaHKoH0QlXq+bKXqfJVC/FyQq/42dkQoWUry0OJOna38/nuNoclMdztIIVuB1wBfbFrXRS9SQohhIMWSSGEcNAiKYQQDgtrkqdOnQJ7fxBTD/cPsBXC9g6mKdr/g6/rZoht18Cfte0IQgghI/FhpRt1tWOr1N2RuGJ9Dey9PIbp7A7wGqd0zROj9U2TZk2S5MBQWbtW4p6FqPlaEsMarU31yujZJcn8FgyBdTOipiXalLcWniela261Fp5yNe3T09VYo7TSbpOW1yP92juPxyL71lolmAnAmmRJbSew1YN/rmWu+6F0tKxr0PGai1pnSLwfe1bWzBkOAbI/HJ73fD+9vkltvohwML1JCiGEgxZJIYRw0CIphBAOCwtEV119Ndg7OztH2+cvbMNY99w5sKcmHmpaSyVEpjm1uzTaQ0Jl1rpd1JJWezH277K1Vfc8pzc3wM4O9o62JxTPNXE0yaShRW4I9ZTAysR1lRX9naL2tYXRqTiGkmG9d2zSIZOazkhl54xelFJZNSan79DqjNyqlstwLZPyxpqkt39NozTxq1VDLGuf0iyLfH4sJ8f+QZm4BVIFa5+HUmmkSXLKqrMvw6P2yTWVf1uGeizkZO4YxwRjW1j/fa1FmqSNzeb4S46vXembkoE1bbMZvUkKIYSDFkkhhHBY2N1+9KMfDfb2dnSxd/f2YGx3H+39/RgutDfAquV18JV8OokpfR16Je910KU+thbdsyvJnWauPXYM7M5g/2i7tbsDY/0UX9E77ejG7jfIByGE0KI/RaMyusUFu9c1u5g7xkwofMqmP3I6XEJusHVX08y/J67ylOdxGmUtdNXZjbLpZ2nquz7svqbO/dSqa1sPMvXdSU7RLLP5qXX8HViZgvedRS39zhyurJzUyoDVbFguYeqV200oHYVheSmBTaFE7KljKBZ+lr8jnAv++xqfx84NToteX8Pwvq1jW0fbPXLFF0FvkkII4aBFUgghHLRICiGEQ1Itk78khBCPMPQmKYQQDlokhRDCQYukEEI4LBwnefvtXwT7gklF/ItPfxrG/uoznwH7zJkzR9v3nT0DY7fe8l6w/96Tnwr24WHsnri1tg5j154+DfZjTkX7caeuhLHv/tf/Auzb/vOvg33u7rvM9t0wdnaApeDODmP7hjOHOPbmD90SmKc/8VvA3jafn9bSujgub36c5N1f/gLY1/1vjwe734txo70ept6xbbsncte+D33gHWA/8+YXg23jHdOMu9rNj8njVLN3vPW3wX7Jy74PbBvfx7F+tTJ6phQcx1T+5m/9R7Bf/aofB9uG93E3TK/7I5fsetPv/2pgXv4PfwBs22mUu44WVFoMbbyu97zr/wX7Od/xXWDb525bdcyyS6fFxtv+8LfAft4L/jHYIxNDy2mIHI8Jc4HG/viP8H5e8CI8z9D8hoZDjNu9+pqrwP7ar/nao+01KpH4r//lD4cm9CYphBAOWiSFEMJBi6QQQjgsrEleeeUVYPdM+aG9/X0YsyW6Qgih04maR1X6+a2b61geKzctZrtUcmxjBfMwT6zHXO6Ta3gc5vJVzPtubWwebfe2DmGMWx2MjGa3M8Z7nUVFWqJtq1DTJLmUVmHziP3cbdbErMbFZdTYhja3pZ8XPJ1grmxI4zXzs8pSavtrtKemNqIj0pqsDlnT0Vr4bKxGyXolU2tHazRMzoHmXHQ7vkjIMWu09jOcu11rN2zP1XAezoW2Nut/bMMMbLinlJ+P1X9pjHVkvEb/PNwKwl4Xp32v0W/78ssvO9re2tpyzzMLvUkKIYSDFkkhhHBY2N22LnMIIaybyt/8X+5ZG1/f10zl57UelqVivvYarIDeLqJrt9bHsJWTm/hafXwjjq+2fVeuS27/mnEFqhU87tkBut/Tcbymw8Nmd3s4whJmI+Ou1qtPc3Vq28Ww4UQ0Dq4ilwtLuQyXcTEbylaxy2j/1ib8d5fKfcFjb6jkPRmTRDA14TYT/P4mGUoAEF7SUJLtgEK8IKSpVmZt/pewUGVypwNik2u7TP1wbuJp7aZOk5W5j1oXyto1kbvtPDt2t+0oS3TMmGStzNQfXCdp7cTxTbBPXXnyaPv4iePueWahN0khhHDQIimEEA5aJIUQwuGiNUnbFe906xSMbVDrhJVOPM1qxz/lddeiJlkMdo+2+2387MktTFM8vmY0yZav4LQoBKZnNLmqi9pni8JaJpP42eEY9cZZjChkZmLCGRqaGC7VhiDxdMclOuI1dc9L6Xmg7khtIUims13+ioawj3xCIU32LE6ISwghZObem1oD2NTXEPwwJa/74yKUFMbVpPkhpnNow561catDOhokX1Nj+wY6kw23Yk2yTVo2dJrkEB9iQprkRjemF65v4P8hnDiBrVmuuCJqkidPnnDPMwu9SQohhIMWSSGEcNAiKYQQDgtrkozVYjqUIraygnFLl10W04KSBu3h6667DuyeiStrk3Zy+gTqC8c7vaPtdOqfZ7CLbW8PTCzkwQHGzQ2oherIXEfRoHeFEEJKem4nxOtkSavWorOavT0LbudqlSludzomLTXP4z0loSFdcIQantUok4ZWr3beNOl5ScItZe1nuV0p2nAZHDRYg+MbbaohjtQ1usVTBR/8fDHXLimGklN4vXatjBez6aX4PWgurknWtWCj7dM1Tuk3WZhWsE3teFnfXN+ImuSpU5gyfcXlJ8E+fnzraHtrC2MoF0FvkkII4aBFUgghHC7a3bbVP7giC1enToxbvNZmlxB5LLnbmybUKBmh27vVxhTHfmEqqgzRnWYGezi+fxCrDe0doDu5TylTI+MGFQ1hOSGEkHIl6MWzBZdyt1vsbpvvKKfQk7xAdzsJ0fXJOMSHGI0pZCa1FXfmV59+0LYhIv7f6DRld9umTpJ7XcvDs4afLshuoa2+U3e3+dPW3W52uMuK0xKjXav6U3HK6uIpjLWwHrPNjq3nUjeHg81PPcxzCn2bkm1+V1yVqnYe+mFsmArjp6kLgQ35CSGEE3K3hRDi4UOLpBBCOGiRFEIIh6RapJyyEEI8QtGbpBBCOGiRFEIIBy2SQgjhsHCcZE24tF3eaKikUkzTw5jmN6GUv60rMcbpjk/+OdgP3HXX0Xaxh10ZexT7l5lUu5w6OP691/4o2H/6b/892BcGg7i9P4CxL2zvgP05Y5+hMlu3fOxDgXniE58C9oGNH+N4No6VM8+Sq2p9/q8/BfYNX/9EsFutGEeaUguDWvybLXdG1/CpT34E7G98wtPmHouj6lInTZHjJD/+iVvA/tYbn4WfNTGzGd0Px+ba++V93/f+t4D93Gd/59xjNZVKgzhBeqZvfdtvB+YlL/5esKFcGM2FJtvyrne/CezveN53gW2/o6Yyc15s5Nve/kawX/yiV87ddzrFWNzhEH8rRRljI7tdjHl+73vfCvZLXvqPwX7c466fuR1CCI95zNeCfd110V438ZUhhNDt+O1kQtCbpBBCuGiRFEIIBy2SQgjhcNG529Vco44tn5W1/FN2O12wV3qxlcJkiDnUFZXsmoyi1jct/HzdIcku+yYf+wLlNQ8o23Vq80gbWteGEEKLSqV1zefzWvkotCEfuKFlaUI5160snpfbebJGackpx7Z+HvzCbd4tl/uaIWab4/h5wQeHmF8PbWIpT53vz957VSshh+Ql3m/L5IUnFEacVPjcKtuKd5Gmr/TsrGSb1hXd5uPNwdMZmzRIb1+Gw6xtvvaYSgxyW1h7770+/u6ZE9QK9sorY3m0q6++ivbFEor9XixN2G5Yf2ahN0khhHDQIimEEA4X7W571JwGE7rBbhHT7WOnwtXNWNqoTUcu2/iKXpjPtnL8r35m9Srs8Li+Gfef7GO3x+khug3pYSyrdmLsu6YhhPDYxz4W7EPjdgzNsUIIYThEezyKrj9XE2fWV/GesSzZ/BAZpp35EkK/h5XnC+Nil1TyisNWisKWIWsoYUauepHbcBl87nmObn6WRTtL/e9oyN0SzRzlECAuBWfndpNrGkIIkwnOJew0ifObXVlrNkkV/NzttfGYd6ymiuETKiM4mcQ5Oq3JNng/Vlo7trXlnuf0Kfy9XnFFdLcvp0rkGxvYRbVluqzWOoougN4khRDCQYukEEI4aJEUQgiHS6JJ1iUN/AebFpY0tG/orq2CbTvGFdSFsZqg5lGa8Bkuk89cTqlMK0YnPE6hC6cmqLMNJvHYBw06YQghPO0pmJa4b9pDbO/swNgOpUDumq6Oe9ThkTlxHMMkpuZ5sPzHXQ0xtbAXPDY2tsCGdgclh4Tgs7M6VV2zQtotvI7c6J1WnwwhhClplCGJdpMKtbc/P9So3n6CNUqjX7aaw8G4E6f9Hmqpo4FDc0y4UYMmyc8dWl84IT8hoGbZpEkekqZuNUq+xHYblxvb8fDyyy93z3PNNVeDfeUVcf/jx4/B2MoK/r9Gltm5Pr/b5Tz0JimEEA5aJIUQwkGLpBBCOFy0JplAK00eo3+xJa4aTtmhOEnbSrIkvZJrh0FcWYPUsPXoR4G9YrSXYxTrNyVZZmpa144nfivMEEJ4wjd+I9j7pizb+QvbMHbhwgWwz5+/YMZwX4Z1mwOjfU5Iv2VND7TEBr1rbQXjMUvz3Dm2bzplTTJquHxNTK+H37f9LB+XNbiyMvolp0oS/Fmrw7F2i/oWlWTLmt85Dikm036+KZY1TRaPyWS91+7fVP7NPg9+Ngy3jbXPukPpuKtr+H8Kx42GbtMMZ3HVVZh6eNllMfWQy5+x9mnXEG77u0jUpN4khRDCQYukEEI4XJoQILJr7rd131r+utyiCsWJ2Z/DS/hE4Ok1vEd3KYylXdmUNzxwSS6k8bYhzW4eV19zGmybXsgpVYMBVkXf2d2N2zu7weObnvANYG+bcKL9PTzugEJRDk3q5WTsu1htquZsXfe84PRA/GwSrNvnh4Otr2N6aGmeNbvQRcHud3QD88J361dXMY3NVjLiFD6WE+x41VClKQRMMw2Bfhskc9Srui/u2nMFHpsOXFV+BaW51zeDNoX02TAodoMvvxyr89jqPVddhb8R5tRp7GCwsRnnRqvF8kHTirQcepMUQggHLZJCCOGgRVIIIRySikUWIYQQR+hNUgghHLRICiGEgxZJIYRwuPhuia6SyYPV3DHu8FdVHKM3P/ixojW+coIjM4r3KrgL3tyzLMesuDIvto7T62z5+xBC2N8/MNsY63j99Y8B+6Mf/TjYD9x/Pm6fx3THC+cxxXFnJ5YL29/H1Llf/pWfBvvVr/pRuubpzO0Q6rGDHINqectbfx3sl730n83dt9YWguzpdDxzO4QQ3vf+t4D9jGe8kD67ePojdIqkGNG/+sxttet+3A3fArb3O+KUSJs+yLGBn/qLW8F+0hO/DWwbz9jtdmkM414rJ830/bfgs3v2s14GdmbimrnD4TXXYGrh13xNTA2+/vqvg7GbbroR7Hvvux/stbWYvry6iqnM9Z+gTbnF+0mDH6v74D5CCCHmokVSCCEctEgKIYTDw9JS1scPy+RSRnb/+gjlylbOmk9ChaupLhU5StpmNkOTrOX0xs9wnimXebLaS7vttwc4dQrzW23urC0tFUIIe6Rv2tzuvT3M62a+/utvANuWZBsM8LOj0Wiu3dS+YWUVtTMs4cX9ZvnTpmVI0uVBoNfFNhGtVtSpOh3KEXfKqjW1OgghhBUqM2c1v6ZWr54myfR6qNN1TL49lzCz97ssW1ubYK+sxnJoV16JLRkeTeUJr33UNUfbPD8ZbsmAv5OmH6xyt4UQ4mFDi6QQQjj8LbjbPuxuW5e6qtiVpTUeWgI2BPKQv13Nj1LyD0M7pzO8oFrYS2LdbRziqtHtdnQz2OVgTp/G6s7TaXRhJtTVcTjEsBjrMu9RWTWG3e3t7V2zvQNje3u7ZMdQo8GBf56VVQxNGQ3N98vyCX02MVM7Tf1pzq6p/b7qoUboUtvybU1VvEMIYXUFy7IVUJbNd9ftLXOJMqbfn+9u82f9UmnuacLm1hbYx49H++qrsVJ+zd2+No6fOIEdD5mVFZREbHRUXaKbz8WE9+lNUgghHLRICiGEgxZJIYRweAiapKMD1AWiRYbm/Eu0ayl/pFHCeE2/pKN66WBk13ZNZm4ufkA7lDTZiydM1svYz++Qx7pU17TNYD2L4XYUW8diKf2TA0xF43YUg8G+2fZDjW64AVPVbKfB4XB+aFEIIUzGUd+bNHS0PHkSw09saFI9LXFK++Zzx2bBYU3LhhD9DU0hQJ1Oa67NIUAdasfR6/Vmbs/iWko1vPyKGPZz1VUYksYhQXbe9Pp+mBZ3dEySxf8T4aGkGYegN0khhHDRIimEEA5aJIUQwuHSxEk2hCkt0+qVSZwiZqxRJtXi+l26zIXMl0mbpM8Hd3+oosiC8PPITIpkSmNt0rSsJrm6thI8Tl+F8ZiTSdQhp1TqbTgaon0Y7YPDhvTHb8B4TKthHpCeyfrmwSBqlAcHqFcyV1yBbX2Hw6h9jkYYTzoeoz2Z2JJsvk4YQggrK4trkl5nFdboGNYkbUorj/X7qEnaVMNjx/z4xUc9+lqwr7761NE2t0s+cRnq1RsbMUWzSWP1f0OJY4WgtEQhhHgY0SIphBAOD0taopsmxP5p7d3Ye6/2X6uTJVxod1/HvQ6Bb2GBV/mar3Cxr/8NoQ7eLWX+38PM3GTTpOD0SOuq5zm6k90eh5fE8U7XT607dmwLbFv5pZXND3cKASve19NZkT6Fn5SlqTbOaYglhgRVVctsc7WnOuxW2u+sFuFWS5216az+98nVpayd0Vzg8DD7fTalwq6trYK9sR7TLtfWcazfx3AiG4bG18vU57a3//xAQ6UlCiHEJUaLpBBCOGiRFEIIh6Ty4gyEEOIRjt4khRDCQYukEEI4aJEUQggHLZJCCOGgRVIIIRy0SAohhIMWSSGEcNAiKYQQDlokhRDC4X8ATsXDVDj+crcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 144 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " data_augmentation (Sequent  (None, 72, 72, 3)            7         ['input_1[0][0]']             \n",
      " ial)                                                                                             \n",
      "                                                                                                  \n",
      " patches_1 (Patches)         (None, None, 108)            0         ['data_augmentation[0][0]']   \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncode  (None, 144, 64)              16192     ['patches_1[0][0]']           \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 144, 64)              128       ['patch_encoder[0][0]']       \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 144, 64)              66368     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 144, 64)              0         ['multi_head_attention[0][0]',\n",
      "                                                                     'patch_encoder[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 144, 64)              128       ['add[0][0]']                 \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 144, 128)             8320      ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 144, 128)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 144, 64)              8256      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 144, 64)              0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 144, 64)              0         ['dropout_1[0][0]',           \n",
      "                                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 144, 64)              128       ['add_1[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 144, 64)              66368     ['layer_normalization_2[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 144, 64)              0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 144, 64)              128       ['add_2[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 144, 128)             8320      ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 144, 128)             0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 144, 64)              8256      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 144, 64)              0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 144, 64)              0         ['dropout_3[0][0]',           \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 144, 64)              128       ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 144, 64)              66368     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 144, 64)              0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_3[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 144, 64)              128       ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 144, 128)             8320      ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 144, 128)             0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 144, 64)              8256      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 144, 64)              0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 144, 64)              0         ['dropout_5[0][0]',           \n",
      "                                                                     'add_4[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 144, 64)              128       ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 144, 64)              66368     ['layer_normalization_6[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 144, 64)              0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_5[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 144, 64)              128       ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 144, 128)             8320      ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 144, 128)             0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 144, 64)              8256      ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 144, 64)              0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 144, 64)              0         ['dropout_7[0][0]',           \n",
      "                                                                     'add_6[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 144, 64)              128       ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 144, 64)              66368     ['layer_normalization_8[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 144, 64)              0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_7[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 144, 64)              128       ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 144, 128)             8320      ['layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 144, 128)             0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 144, 64)              8256      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 144, 64)              0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 144, 64)              0         ['dropout_9[0][0]',           \n",
      "                                                                     'add_8[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 144, 64)              128       ['add_9[0][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 144, 64)              66368     ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 144, 64)              0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_9[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 144, 64)              128       ['add_10[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 144, 128)             8320      ['layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 144, 128)             0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 144, 64)              8256      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 144, 64)              0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 144, 64)              0         ['dropout_11[0][0]',          \n",
      "                                                                     'add_10[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 144, 64)              128       ['add_11[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 144, 64)              66368     ['layer_normalization_12[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 144, 64)              0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_11[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 144, 64)              128       ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 144, 128)             8320      ['layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 144, 128)             0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 144, 64)              8256      ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 144, 64)              0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 144, 64)              0         ['dropout_13[0][0]',          \n",
      "                                                                     'add_12[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 144, 64)              128       ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 144, 64)              66368     ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 144, 64)              0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_13[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 144, 64)              128       ['add_14[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 144, 128)             8320      ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 144, 128)             0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 144, 64)              8256      ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 144, 64)              0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 144, 64)              0         ['dropout_15[0][0]',          \n",
      "                                                                     'add_14[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 144, 64)              128       ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 9216)                 0         ['layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 9216)                 0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 2048)                 1887641   ['dropout_16[0][0]']          \n",
      "                                                          6                                       \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 2048)                 0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 1024)                 2098176   ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (None, 1024)                 0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 100)                  102500    ['dropout_18[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21759019 (83.00 MB)\n",
      "Trainable params: 21759012 (83.00 MB)\n",
      "Non-trainable params: 7 (32.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vit_classifier = create_vit_classifier()\n",
    "print(vit_classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 20:04:26.538899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 43s 205ms/step - loss: 4.4730 - accuracy: 0.0451 - top-5-accuracy: 0.1611 - val_loss: 3.8739 - val_accuracy: 0.1010 - val_top-5-accuracy: 0.3150\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 3.9199 - accuracy: 0.0975 - top-5-accuracy: 0.2987 - val_loss: 3.5410 - val_accuracy: 0.1600 - val_top-5-accuracy: 0.4256\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 3.6639 - accuracy: 0.1355 - top-5-accuracy: 0.3748 - val_loss: 3.3130 - val_accuracy: 0.2000 - val_top-5-accuracy: 0.4824\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 3.4798 - accuracy: 0.1652 - top-5-accuracy: 0.4290 - val_loss: 3.1841 - val_accuracy: 0.2294 - val_top-5-accuracy: 0.5196\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 3.3321 - accuracy: 0.1920 - top-5-accuracy: 0.4694 - val_loss: 3.0691 - val_accuracy: 0.2476 - val_top-5-accuracy: 0.5452\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 36s 205ms/step - loss: 3.1965 - accuracy: 0.2172 - top-5-accuracy: 0.5081 - val_loss: 2.9393 - val_accuracy: 0.2668 - val_top-5-accuracy: 0.5660\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 3.0622 - accuracy: 0.2442 - top-5-accuracy: 0.5395 - val_loss: 2.8248 - val_accuracy: 0.2972 - val_top-5-accuracy: 0.5986\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.9507 - accuracy: 0.2640 - top-5-accuracy: 0.5664 - val_loss: 2.6558 - val_accuracy: 0.3262 - val_top-5-accuracy: 0.6340\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.8497 - accuracy: 0.2854 - top-5-accuracy: 0.5922 - val_loss: 2.5772 - val_accuracy: 0.3472 - val_top-5-accuracy: 0.6562\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.7492 - accuracy: 0.3082 - top-5-accuracy: 0.6156 - val_loss: 2.5160 - val_accuracy: 0.3506 - val_top-5-accuracy: 0.6652\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.6501 - accuracy: 0.3271 - top-5-accuracy: 0.6403 - val_loss: 2.4500 - val_accuracy: 0.3674 - val_top-5-accuracy: 0.6820\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.5668 - accuracy: 0.3436 - top-5-accuracy: 0.6562 - val_loss: 2.3907 - val_accuracy: 0.3840 - val_top-5-accuracy: 0.6918\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.4939 - accuracy: 0.3583 - top-5-accuracy: 0.6726 - val_loss: 2.3493 - val_accuracy: 0.3880 - val_top-5-accuracy: 0.7024\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 36s 206ms/step - loss: 2.4258 - accuracy: 0.3707 - top-5-accuracy: 0.6879 - val_loss: 2.2871 - val_accuracy: 0.4066 - val_top-5-accuracy: 0.7078\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.3578 - accuracy: 0.3825 - top-5-accuracy: 0.7033 - val_loss: 2.2443 - val_accuracy: 0.4216 - val_top-5-accuracy: 0.7210\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.2889 - accuracy: 0.4011 - top-5-accuracy: 0.7184 - val_loss: 2.2229 - val_accuracy: 0.4248 - val_top-5-accuracy: 0.7262\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 36s 204ms/step - loss: 2.2217 - accuracy: 0.4146 - top-5-accuracy: 0.7294 - val_loss: 2.1750 - val_accuracy: 0.4308 - val_top-5-accuracy: 0.7340\n",
      "Epoch 18/100\n",
      "  8/176 [>.............................] - ETA: 32s - loss: 2.1877 - accuracy: 0.4209 - top-5-accuracy: 0.7363"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m history\n\u001b[1;32m     40\u001b[0m vit_classifier \u001b[39m=\u001b[39m create_vit_classifier()\n\u001b[0;32m---> 41\u001b[0m history \u001b[39m=\u001b[39m run_experiment(vit_classifier)\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     15\u001b[0m checkpoint_filepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/tmp/checkpoint\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     17\u001b[0m     checkpoint_filepath,\n\u001b[1;32m     18\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     24\u001b[0m     x\u001b[39m=\u001b[39;49mx_train,\n\u001b[1;32m     25\u001b[0m     y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m     26\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     27\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     28\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     29\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback],\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m model\u001b[39m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m     33\u001b[0m _, accuracy, top_5_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1749\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    625\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    626\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1055\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.conda_envs/waldo_tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1108\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waldo_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
